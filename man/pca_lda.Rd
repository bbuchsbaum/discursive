% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pca_lda.R
\name{pca_lda}
\alias{pca_lda}
\title{PCA followed by Linear Discriminant Analysis}
\usage{
pca_lda(
  X,
  Y,
  preproc = center(),
  dp = min(dim(X)),
  di = dp - 1,
  dl = length(unique(Y)) - 1
)
}
\arguments{
\item{X}{A numeric matrix of size \code{n x d}, where \code{n} is the number of samples (rows)
and \code{d} is the number of features (columns).}

\item{Y}{A factor or numeric vector of length \code{n} representing class labels for each sample.
If numeric, it will be converted to a factor.}

\item{preproc}{A preprocessing function from the \code{multivarious} package (e.g. \code{center()}, \code{scale()})
to apply to the data before PCA. Defaults to centering.}

\item{dp}{Integer. The dimension of the initial PCA projection. Defaults to \code{min(dim(X))}, i.e.,
the smaller of the number of samples or features. Must be at least 2 and at most \code{min(n,d)}.}

\item{di}{Integer. The dimension of the within-class projection, typically \code{dp-1}. Defaults to \code{dp-1}.}

\item{dl}{Integer. The dimension of the between-class projection. Defaults to \code{length(unique(Y))-1}, which
is often the maximum number of discriminative axes for LDA.}
}
\value{
An object of class \code{discriminant_projector} (from \code{multivarious}) containing:
\itemize{
\item \code{rotation}: The final projection matrix of size \code{d x dl}, mapping from original features to \code{dl}-dimensional space.
\item \code{s}: The projected data scores of size \code{n x dl}, where each row is a sample in the reduced space.
\item \code{sdev}: The standard deviations of each dimension in the projected space.
\item \code{labels}: The class labels associated with each sample.
\item \code{dp}, \code{di}, \code{dl}: The specified or inferred PCA/LDA dimensions.
\item \code{preproc}: The preprocessing object used.
}
}
\description{
This function applies Principal Component Analysis (PCA) followed by Linear Discriminant Analysis (LDA) to a given dataset.
The data is first projected onto \code{dp} principal components, then further transformed via a two-step LDA procedure:
an intermediate within-class projection of dimension \code{di}, followed by a final between-class projection of dimension \code{dl}.
This sequence of transformations aims to reduce dimensionality while enhancing class separability.
}
\details{
The function proceeds through the following steps:
\enumerate{
\item \strong{Preprocessing}: The data \code{X} is preprocessed using the specified \code{preproc} function.
\item \strong{PCA Projection}: The preprocessed data is projected onto the first \code{dp} principal components.
\item \strong{Within-Class Scatter}: The within-class scatter matrix \code{Sw} is computed in the PCA-transformed space.
\item \strong{Between-Class Scatter}: The between-class scatter matrix \code{Sb} is computed in the PCA-transformed space.
\item \strong{Within-Class Projection}: The eigen-decomposition of \code{Sw} is used to derive an intermediate projection of dimension \code{di}.
\item \strong{Between-Class Projection}: The projected group means are subjected to PCA to derive a final projection of dimension \code{dl}.
\item \strong{Final Projection}: The data is ultimately projected onto the \code{dl}-dimensional subspace that maximizes class separation.
}
}
\examples{
\dontrun{
data(iris)
X <- as.matrix(iris[, 1:4])
Y <- iris[, 5]
# Reduce to a space of dp=4, di=3, dl=2 for illustration
res <- pca_lda(X, Y, di=3)
}
}
\seealso{
\code{\link[multivarious]{pca}}, \code{\link[RSpectra]{eigs_sym}}
}
